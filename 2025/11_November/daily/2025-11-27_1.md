# 🧾 Daily Report - {{2025.11.27}}

**Project / Course:** 
**Author:** MARKCH

---

## 1. 오늘의 목표
- AI응용 : CNN 모델 구조 및 추적 알고리즘 실습 (9h)
- 코테
- 일일 로그 작성 

## 2. 수행 내용
- AI응용 : 주요 CNN 아키텍처 및 CamShift 알고리즘 학습
    - **LeNet**: 초기 CNN 구조 이해 및 구현
    - **AlexNet**: 심층 신경망의 시초, ReLU 및 Dropout 적용
    - **VGG13**: 3x3 필터를 활용한 깊은 네트워크 구조 학습
    - **GoogleNet**: Inception 모듈을 활용한 효율적인 연산 구조 학습
    - **CamShift**: MeanShift의 한계를 극복한 객체 추적 알고리즘 실습
- 추가학습 : 각 모델의 파라미터 수 및 연산량 비교
- 일일 로그 작성 :
    - 학습한 모델들의 구조적 특징과 발전 과정을 정리

## 3. 결과 / 진척도
- AI응용 :
    - **LeNet**
      - 세션: 1회
      - 주요 학습: Convolution 및 Subsampling 레이어의 기본 동작 원리 파악
    - **AlexNet**
      - 세션: 1회
      - 주요 학습: 대용량 데이터셋 처리를 위한 깊은 구조와 GPU 활용의 중요성 이해
    - **VGG13**
      - 세션: 1회
      - 주요 학습: 작은 필터(3x3)의 중첩 사용이 주는 이점(비선형성 증가, 파라미터 감소) 확인
    - **GoogleNet**
      - 세션: 1회
      - 주요 학습: 1x1 Convolution을 통한 차원 축소 및 다양한 커널 크기의 병렬 처리(Inception) 이해
    - **CamShift**
      - 세션: 1회
      - 주요 학습: 객체의 크기 변화와 회전에 대응하는 적응형 윈도우 추적 방식 구현

## 4. 트러블 슈팅 및 문제해결
- **CNN 모델 공통**: 구현 시 입출력 텐서의 차원(Dimension) 불일치 문제 빈번 발생. `summary()` 함수 등을 활용하여 레이어별 출력 형태를 수시로 확인하며 디버깅.
- **VGG13**: 모델이 깊어짐에 따라 학습 속도가 저하되고 과적합 우려. 데이터 증강(Data Augmentation) 및 배치 정규화(Batch Normalization) 기법의 필요성 체감.
- **GoogleNet**: 복잡한 Inception 모듈 구현 시 코드 구조화가 어려움. 모듈을 함수나 클래스로 분리하여 재사용성을 높이는 방식으로 해결.
- **CamShift**: 초기 검색 윈도우 위치 설정이 잘못되면 수렴하지 않는 문제. 초기 객체 검출(ROI 설정)의 정확도가 중요함을 확인.

## 5. 분석 / 인사이트
- **결과 요약**: LeNet에서 GoogleNet으로 이어지는 CNN의 발전사를 코드로 구현하며, 모델이 어떻게 더 깊고(Deep) 넓게(Wide) 발전해왔는지 이해함. 또한 CamShift를 통해 고전적 컴퓨터 비전 추적 기법의 원리를 다짐.
- **트러블 슈팅 기반 인사이트**:
  - 딥러닝 모델 설계 시 '차원 관리'가 핵심임.
  - 모델의 깊이(Depth)뿐만 아니라 너비(Width)와 연산 효율성도 중요한 설계 요소임(GoogleNet).
  - 추적 알고리즘은 초기화와 특징 추출(색상 히스토그램 등)의 강건함에 크게 의존함.
- **다음 단계**: ResNet 등 잔차 학습(Residual Learning) 모델 학습 및 딥러닝 기반 객체 검출/추적 모델(YOLO 등)과의 비교 학습 필요.

## 6. 내일 계획
- AI응용 수강 : 최신 딥러닝 모델 및 응용 실습 (9h)
- 코테
- 일일 로그 작성 
